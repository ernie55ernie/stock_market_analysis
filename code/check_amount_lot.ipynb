{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602851d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Define price data directory\n",
    "price_data_dir = \"../data_sample/price/\"\n",
    "amount_data_dir = \"../data_sample/chip/amount/\"\n",
    "lot_data_dir = \"../data_sample/chip/lot/\"\n",
    "os.makedirs(price_data_dir, exist_ok=True)  # Ensure price directory exists\n",
    "\n",
    "def get_stock_codes():\n",
    "    print('Downloading stock data...')\n",
    "    urls = {\n",
    "        2: \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=2\",\n",
    "        4: \"https://isin.twse.com.tw/isin/C_public.jsp?strMode=4\"\n",
    "    }\n",
    "\n",
    "    stock_dict = {}\n",
    "    for mode, url in urls.items():\n",
    "        res = requests.get(url)\n",
    "        if res.status_code == 200:\n",
    "            df = pd.read_html(res.text)[0]\n",
    "            df.columns = ['full_name', 'isin_code', 'listed_date', 'market_type', 'industry_type', 'cfic_code', 'remarks']\n",
    "            \n",
    "            stock_start = df[df['full_name'].str.contains('股票', na=False)].index[0] + 1\n",
    "            stock_end = df[df['full_name'].str.contains('上市認購\\(售\\)權證', na=False)].index[0] if mode == 2 else df[df['full_name'].str.contains('特別股', na=False)].index[0]\n",
    "            \n",
    "            stock_df = df.iloc[stock_start:stock_end]\n",
    "\n",
    "            # Extract stock code and clean it\n",
    "            stock_df['code'] = stock_df['full_name'].str.extract(r'(\\d{4})')  # Extract numeric stock codes\n",
    "\n",
    "            # Create dictionary with stock code as key and market type as value\n",
    "            for _, row in stock_df.dropna(subset=['code']).iterrows():\n",
    "                stock_dict[row['code']] = row['market_type']\n",
    "\n",
    "    return stock_dict\n",
    "\n",
    "# Load stock codes and their market type\n",
    "stock_dict = get_stock_codes()\n",
    "\n",
    "# Function to determine the correct Yahoo Finance stock suffix\n",
    "def get_stock_suffix(market_type):\n",
    "    return \".TW\" if market_type == \"上市\" else \".TWO\"\n",
    "\n",
    "# Function to fetch historical stock prices with retry and caching\n",
    "def query_historical_price(stock_code, market_type, end_date, period=390, max_retries=5, retry_delay=300):\n",
    "    suffix = get_stock_suffix(market_type)\n",
    "    end_date = (datetime.strptime(end_date, \"%Y-%m-%d\") + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    start_date = (datetime.strptime(end_date, \"%Y-%m-%d\") - pd.Timedelta(days=period)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    cache_path = os.path.join(price_data_dir, f\"{stock_code}_{end_date}_{period}.csv\")\n",
    "\n",
    "    # Check if cached data exists\n",
    "    if os.path.exists(cache_path):\n",
    "        logging.info(f\"Loading cached price data for {stock_code}{suffix} from {cache_path}\")\n",
    "        try:\n",
    "            data = pd.read_csv(cache_path, parse_dates=['Date'])\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error reading cached file {cache_path}: {e}, refetching data...\")\n",
    "\n",
    "    logging.info(f\"Fetching historical data for {stock_code}{suffix} from {start_date} to {end_date}\")\n",
    "\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            data = yf.download(f\"{stock_code}{suffix}\", start=start_date, end=end_date)\n",
    "            if data.empty:\n",
    "                logging.warning(f\"No data found for {stock_code}{suffix}\")\n",
    "                return None\n",
    "\n",
    "            data = data.reset_index()\n",
    "            data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "            # Save fetched data to cache\n",
    "            data.to_csv(cache_path, index=False)\n",
    "            logging.info(f\"Saved price data to {cache_path}\")\n",
    "\n",
    "            return data\n",
    "\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            logging.error(f\"Connection error fetching data for {stock_code}{suffix}: {e}\")\n",
    "            attempt += 1\n",
    "            if attempt < max_retries:\n",
    "                logging.info(f\"Retrying in {retry_delay // 60} minutes... (Attempt {attempt}/{max_retries})\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                logging.error(f\"Failed to fetch data for {stock_code}{suffix} after {max_retries} attempts.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error fetching data for {stock_code}{suffix}: {e}\")\n",
    "            return None\n",
    "\n",
    "# Function to process buy/sell data and compare with stock prices\n",
    "def process_chip_data(end_date):\n",
    "    # Read all CSV files in the amount and lot directories\n",
    "    amount_files = [f for f in os.listdir(amount_data_dir) if f.endswith(f\"{end_date}.csv\")]\n",
    "    lot_files = [f for f in os.listdir(lot_data_dir) if f.endswith(f\"{end_date}.csv\")]\n",
    "\n",
    "    if not amount_files or not lot_files:\n",
    "        logging.warning(f\"No amount/lot data found for {end_date}.\")\n",
    "        return\n",
    "\n",
    "    # Combine all CSV files\n",
    "    df_amount = pd.concat([pd.read_csv(os.path.join(amount_data_dir, f)) for f in amount_files], ignore_index=True)\n",
    "    df_lot = pd.concat([pd.read_csv(os.path.join(lot_data_dir, f)) for f in lot_files], ignore_index=True)\n",
    "\n",
    "    # Merge amount and lot data on common keys\n",
    "    df = pd.merge(df_amount, df_lot, on=[\"broker\", \"branch\", \"date\", \"stock_code\"], suffixes=('_amount', '_lot'))\n",
    "\n",
    "    # Calculate average buy and sell prices\n",
    "    df['avg_buy_price'] = df['buy_amount'] / df['buy_lot']\n",
    "    df['avg_sell_price'] = df['sell_amount'] / df['sell_lot']\n",
    "\n",
    "    # Drop rows where lot is zero (to avoid division errors)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['avg_buy_price', 'avg_sell_price'])\n",
    "\n",
    "    # Fetch stock price data for each unique stock code\n",
    "    unique_stocks = df['stock_code'].unique()\n",
    "    stock_price_data = {}\n",
    "\n",
    "    for stock_code in unique_stocks:\n",
    "        # Fetch stock price data\n",
    "        market_type = stock_dict.get(stock_code, \"上市\")\n",
    "        stock_data = query_historical_price(stock_code, market_type, end_date)\n",
    "\n",
    "        if stock_data is None or stock_data.empty:\n",
    "            logging.warning(f\"Skipping {stock_code}, no stock data found.\")\n",
    "            continue\n",
    "\n",
    "        # Store latest stock price for comparison\n",
    "        latest_stock_data = stock_data[stock_data['Date'] == end_date]\n",
    "        if latest_stock_data.empty:\n",
    "            logging.warning(f\"No stock price found for {stock_code} on {end_date}.\")\n",
    "            continue\n",
    "\n",
    "        stock_price_data[stock_code] = {\n",
    "            \"high\": latest_stock_data[\"High\"].values[0],\n",
    "            \"low\": latest_stock_data[\"Low\"].values[0]\n",
    "        }\n",
    "        \n",
    "    # Check if avg prices are within the high-low range\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        stock_code = row[\"stock_code\"]\n",
    "        if stock_code in stock_price_data:\n",
    "            high, low = stock_price_data[stock_code][\"high\"], stock_price_data[stock_code][\"low\"]\n",
    "            buy_within_range = low <= row[\"avg_buy_price\"] <= high\n",
    "            sell_within_range = low <= row[\"avg_sell_price\"] <= high\n",
    "\n",
    "            results.append({\n",
    "                \"stock_code\": stock_code,\n",
    "                \"date\": end_date,\n",
    "                \"avg_buy_price\": row[\"avg_buy_price\"],\n",
    "                \"avg_sell_price\": row[\"avg_sell_price\"],\n",
    "                \"high\": high,\n",
    "                \"low\": low,\n",
    "                \"buy_within_range\": buy_within_range,\n",
    "                \"sell_within_range\": sell_within_range\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame and display results\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results, results\n",
    "\n",
    "# Example usage\n",
    "end_date = \"2025-02-07\"  # Change to required date\n",
    "df_results, results = process_chip_data(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
